wandb: Currently logged in as: kenevoldsen. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.3
wandb: Run data is saved locally in /faststorage/project/NLPPred/github/snip/wandb/run-20221001_012731-1kzcwreq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-bird-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kenevoldsen/local%20mlp
wandb: üöÄ View run at https://wandb.ai/kenevoldsen/local%20mlp/runs/1kzcwreq
/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
Using 16bit native Automatic Mixed Precision (AMP)
/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:57: LightningDeprecationWarning: Setting `Trainer(weights_save_path=)` has been deprecated in v1.6 and will be removed in v1.8. Please pass ``dirpath`` directly to the `ModelCheckpoint` callback
  rank_zero_deprecation(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]Finding best initial lr:   2%|‚ñè         | 2/100 [00:00<00:05, 19.47it/s]Finding best initial lr:   4%|‚ñç         | 4/100 [00:00<00:15,  6.02it/s]Finding best initial lr:   8%|‚ñä         | 8/100 [00:01<00:14,  6.14it/s]Finding best initial lr:  12%|‚ñà‚ñè        | 12/100 [00:02<00:15,  5.57it/s]Finding best initial lr:  16%|‚ñà‚ñå        | 16/100 [00:02<00:13,  6.06it/s]Finding best initial lr:  20%|‚ñà‚ñà        | 20/100 [00:03<00:12,  6.58it/s]Finding best initial lr:  24%|‚ñà‚ñà‚ñç       | 24/100 [00:03<00:11,  6.81it/s]Finding best initial lr:  26%|‚ñà‚ñà‚ñå       | 26/100 [00:03<00:09,  7.68it/s]Finding best initial lr:  28%|‚ñà‚ñà‚ñä       | 28/100 [00:04<00:12,  5.63it/s]Finding best initial lr:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [00:05<00:11,  5.88it/s]Finding best initial lr:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [00:05<00:10,  6.25it/s]Finding best initial lr:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [00:06<00:09,  6.31it/s]Finding best initial lr:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [00:06<00:08,  6.47it/s]Finding best initial lr:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [00:07<00:08,  6.25it/s]Finding best initial lr:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [00:08<00:07,  6.24it/s]Finding best initial lr:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [00:08<00:06,  6.39it/s]Finding best initial lr:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [00:09<00:06,  6.26it/s]Finding best initial lr:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [00:10<00:05,  6.36it/s]Finding best initial lr:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [00:10<00:05,  6.38it/s]Finding best initial lr:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [00:11<00:04,  6.47it/s]Finding best initial lr:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [00:12<00:03,  6.20it/s]Finding best initial lr:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [00:12<00:03,  6.44it/s]Finding best initial lr:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [00:13<00:02,  6.66it/s]Finding best initial lr:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [00:13<00:02,  6.46it/s]
`Trainer.fit` stopped: `max_steps=85` reached.
LR finder stopped early after 85 steps due to diverging loss.
Restoring states from the checkpoint path at models/.lr_find_9e7c7e98-49d3-4094-9374-e6f7165c8bae.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name    | Type    | Params
------------------------------------
0 | encoder | MLP     | 230 K 
1 | decoder | MLP     | 231 K 
2 | loss    | MSELoss | 0     
------------------------------------
462 K     Trainable params
0         Non-trainable params
462 K     Total params
0.924     Total estimated model params size (MB)
Training: 0it [00:00, ?it/s]Training: 0it [00:00, ?it/s]Epoch 0: : 0it [00:00, ?it/s]Epoch 0: : 1it [00:01,  1.18s/it]Epoch 0: : 1it [00:01,  1.18s/it, loss=86.8, v_num=wreq]Epoch 0: : 2it [00:01,  1.67it/s, loss=86.8, v_num=wreq]Epoch 0: : 2it [00:01,  1.66it/s, loss=86.9, v_num=wreq]Epoch 0: : 3it [00:01,  2.46it/s, loss=86.9, v_num=wreq]Epoch 0: : 3it [00:01,  2.46it/s, loss=86.9, v_num=wreq]Epoch 0: : 4it [00:01,  2.27it/s, loss=86.9, v_num=wreq]Epoch 0: : 4it [00:01,  2.26it/s, loss=86.9, v_num=wreq]Epoch 0: : 5it [00:01,  2.82it/s, loss=86.9, v_num=wreq]Epoch 0: : 5it [00:01,  2.81it/s, loss=86.9, v_num=wreq]Epoch 0: : 6it [00:01,  3.36it/s, loss=86.9, v_num=wreq]Epoch 0: : 6it [00:01,  3.36it/s, loss=86.9, v_num=wreq]Epoch 0: : 7it [00:01,  3.90it/s, loss=86.9, v_num=wreq]Epoch 0: : 7it [00:01,  3.90it/s, loss=86.9, v_num=wreq]Epoch 0: : 8it [00:02,  3.34it/s, loss=86.9, v_num=wreq]Epoch 0: : 8it [00:02,  3.34it/s, loss=86.9, v_num=wreq]Epoch 0: : 9it [00:02,  3.73it/s, loss=86.9, v_num=wreq]Epoch 0: : 9it [00:02,  3.73it/s, loss=86.9, v_num=wreq]Epoch 0: : 10it [00:02,  4.12it/s, loss=86.9, v_num=wreq]Epoch 0: : 10it [00:02,  4.12it/s, loss=86.9, v_num=wreq]Epoch 0: : 11it [00:02,  4.50it/s, loss=86.9, v_num=wreq]Epoch 0: : 11it [00:02,  4.50it/s, loss=86.9, v_num=wreq]Epoch 0: : 12it [00:02,  4.10it/s, loss=86.9, v_num=wreq]Epoch 0: : 12it [00:02,  4.10it/s, loss=86.9, v_num=wreq]Epoch 0: : 13it [00:02,  4.42it/s, loss=86.9, v_num=wreq]Epoch 0: : 13it [00:02,  4.41it/s, loss=86.9, v_num=wreq]Epoch 0: : 14it [00:02,  4.73it/s, loss=86.9, v_num=wreq]Epoch 0: : 14it [00:02,  4.73it/s, loss=86.9, v_num=wreq]Epoch 0: : 15it [00:02,  5.04it/s, loss=86.9, v_num=wreq]Epoch 0: : 15it [00:02,  5.04it/s, loss=86.8, v_num=wreq]Epoch 0: : 16it [00:03,  4.63it/s, loss=86.8, v_num=wreq]Epoch 0: : 16it [00:03,  4.63it/s, loss=86.8, v_num=wreq]Epoch 0: : 17it [00:03,  4.89it/s, loss=86.8, v_num=wreq]Epoch 0: : 17it [00:03,  4.89it/s, loss=86.7, v_num=wreq]Epoch 0: : 18it [00:03,  5.15it/s, loss=86.7, v_num=wreq]Epoch 0: : 18it [00:03,  5.15it/s, loss=86.7, v_num=wreq]Epoch 0: : 19it [00:03,  5.40it/s, loss=86.7, v_num=wreq]Epoch 0: : 19it [00:03,  5.40it/s, loss=86.6, v_num=wreq]Epoch 0: : 20it [00:03,  5.03it/s, loss=86.6, v_num=wreq]Epoch 0: : 20it [00:03,  5.02it/s, loss=1.12, v_num=wreq]Epoch 0: : 21it [00:03,  5.25it/s, loss=1.12, v_num=wreq]Epoch 0: : 21it [00:04,  5.25it/s, loss=1.01, v_num=wreq]Epoch 0: : 22it [00:04,  5.48it/s, loss=1.01, v_num=wreq]Epoch 0: : 22it [00:04,  5.48it/s, loss=0.945, v_num=wreq]Epoch 0: : 23it [00:04,  5.69it/s, loss=0.945, v_num=wreq]Epoch 0: : 23it [00:04,  5.69it/s, loss=0.885, v_num=wreq]Epoch 0: : 24it [00:04,  5.31it/s, loss=0.885, v_num=wreq]Epoch 0: : 24it [00:04,  5.31it/s, loss=0.87, v_num=wreq] Epoch 0: : 25it [00:04,  5.50it/s, loss=0.87, v_num=wreq]Epoch 0: : 25it [00:04,  5.50it/s, loss=0.854, v_num=wreq]Epoch 0: : 26it [00:04,  5.70it/s, loss=0.854, v_num=wreq]Epoch 0: : 26it [00:04,  5.70it/s, loss=0.841, v_num=wreq]Epoch 0: : 27it [00:04,  5.89it/s, loss=0.841, v_num=wreq]Epoch 0: : 27it [00:04,  5.89it/s, loss=0.828, v_num=wreq]Epoch 0: : 28it [00:05,  5.42it/s, loss=0.828, v_num=wreq]Epoch 0: : 28it [00:05,  5.42it/s, loss=0.813, v_num=wreq]Epoch 0: : 29it [00:05,  5.60it/s, loss=0.813, v_num=wreq]Epoch 0: : 29it [00:05,  5.59it/s, loss=0.804, v_num=wreq]Epoch 0: : 30it [00:05,  5.77it/s, loss=0.804, v_num=wreq]Epoch 0: : 30it [00:05,  5.77it/s, loss=0.794, v_num=wreq]Epoch 0: : 31it [00:05,  5.94it/s, loss=0.794, v_num=wreq]Epoch 0: : 31it [00:05,  5.94it/s, loss=0.787, v_num=wreq]Epoch 0: : 32it [00:05,  5.54it/s, loss=0.787, v_num=wreq]Epoch 0: : 32it [00:05,  5.54it/s, loss=0.782, v_num=wreq]Epoch 0: : 33it [00:05,  5.69it/s, loss=0.782, v_num=wreq]Epoch 0: : 33it [00:05,  5.69it/s, loss=0.777, v_num=wreq]Epoch 0: : 34it [00:05,  5.85it/s, loss=0.777, v_num=wreq]Epoch 0: : 34it [00:05,  5.85it/s, loss=0.772, v_num=wreq]Epoch 0: : 35it [00:05,  6.00it/s, loss=0.772, v_num=wreq]Epoch 0: : 35it [00:05,  6.00it/s, loss=0.769, v_num=wreq]Epoch 0: : 36it [00:06,  5.71it/s, loss=0.769, v_num=wreq]Epoch 0: : 36it [00:06,  5.71it/s, loss=0.766, v_num=wreq]Epoch 0: : 37it [00:06,  5.78it/s, loss=0.766, v_num=wreq]Epoch 0: : 37it [00:06,  5.78it/s, loss=0.763, v_num=wreq]Epoch 0: : 38it [00:06,  5.92it/s, loss=0.763, v_num=wreq]Epoch 0: : 38it [00:06,  5.92it/s, loss=0.76, v_num=wreq] Epoch 0: : 39it [00:06,  6.06it/s, loss=0.76, v_num=wreq]Epoch 0: : 39it [00:06,  6.06it/s, loss=0.758, v_num=wreq]Epoch 0: : 40it [00:06,  5.86it/s, loss=0.758, v_num=wreq]Epoch 0: : 40it [00:06,  5.86it/s, loss=0.755, v_num=wreq]Epoch 0: : 41it [00:06,  5.92it/s, loss=0.755, v_num=wreq]Epoch 0: : 41it [00:06,  5.92it/s, loss=0.754, v_num=wreq]Epoch 0: : 42it [00:06,  6.05it/s, loss=0.754, v_num=wreq]Epoch 0: : 42it [00:06,  6.05it/s, loss=0.752, v_num=wreq]Epoch 0: : 43it [00:06,  6.18it/s, loss=0.752, v_num=wreq]Epoch 0: : 43it [00:06,  6.18it/s, loss=0.75, v_num=wreq] Epoch 0: : 44it [00:07,  5.94it/s, loss=0.75, v_num=wreq]Epoch 0: : 44it [00:07,  5.94it/s, loss=0.749, v_num=wreq]Epoch 0: : 45it [00:07,  6.04it/s, loss=0.749, v_num=wreq]Epoch 0: : 45it [00:07,  6.03it/s, loss=0.747, v_num=wreq]Epoch 0: : 46it [00:07,  6.16it/s, loss=0.747, v_num=wreq]Epoch 0: : 46it [00:07,  6.16it/s, loss=0.745, v_num=wreq]Epoch 0: : 47it [00:07,  6.28it/s, loss=0.745, v_num=wreq]Epoch 0: : 47it [00:07,  6.28it/s, loss=0.744, v_num=wreq]Epoch 0: : 48it [00:07,  6.02it/s, loss=0.744, v_num=wreq]Epoch 0: : 48it [00:07,  6.02it/s, loss=0.743, v_num=wreq]Epoch 0: : 49it [00:08,  6.09it/s, loss=0.743, v_num=wreq]Epoch 0: : 49it [00:08,  6.09it/s, loss=0.741, v_num=wreq]Epoch 0: : 50it [00:08,  6.21it/s, loss=0.741, v_num=wreq]Epoch 0: : 50it [00:08,  6.21it/s, loss=0.74, v_num=wreq] Epoch 0: : 51it [00:08,  6.32it/s, loss=0.74, v_num=wreq]Epoch 0: : 51it [00:08,  6.32it/s, loss=0.739, v_num=wreq]Epoch 0: : 52it [00:08,  6.02it/s, loss=0.739, v_num=wreq]Epoch 0: : 52it [00:08,  6.02it/s, loss=0.738, v_num=wreq]Epoch 0: : 53it [00:08,  6.13it/s, loss=0.738, v_num=wreq]Epoch 0: : 53it [00:08,  6.13it/s, loss=0.737, v_num=wreq]Epoch 0: : 54it [00:08,  6.23it/s, loss=0.737, v_num=wreq]Epoch 0: : 54it [00:08,  6.23it/s, loss=0.736, v_num=wreq]Epoch 0: : 55it [00:08,  6.34it/s, loss=0.736, v_num=wreq]Epoch 0: : 55it [00:08,  6.34it/s, loss=0.735, v_num=wreq]Epoch 0: : 56it [00:09,  6.03it/s, loss=0.735, v_num=wreq]Epoch 0: : 56it [00:09,  6.03it/s, loss=0.735, v_num=wreq]Epoch 0: : 57it [00:09,  6.13it/s, loss=0.735, v_num=wreq]Epoch 0: : 57it [00:09,  6.13it/s, loss=0.734, v_num=wreq]Epoch 0: : 58it [00:09,  6.22it/s, loss=0.734, v_num=wreq]Epoch 0: : 58it [00:09,  6.22it/s, loss=0.734, v_num=wreq]Epoch 0: : 59it [00:09,  6.32it/s, loss=0.734, v_num=wreq]Epoch 0: : 59it [00:09,  6.32it/s, loss=0.734, v_num=wreq]Epoch 0: : 60it [00:09,  6.08it/s, loss=0.734, v_num=wreq]Epoch 0: : 60it [00:09,  6.08it/s, loss=0.733, v_num=wreq]Epoch 0: : 61it [00:09,  6.17it/s, loss=0.733, v_num=wreq]Epoch 0: : 61it [00:09,  6.17it/s, loss=0.733, v_num=wreq]Epoch 0: : 62it [00:09,  6.26it/s, loss=0.733, v_num=wreq]Epoch 0: : 62it [00:09,  6.26it/s, loss=0.733, v_num=wreq]Epoch 0: : 63it [00:09,  6.35it/s, loss=0.733, v_num=wreq]Epoch 0: : 63it [00:09,  6.35it/s, loss=0.733, v_num=wreq]Epoch 0: : 64it [00:10,  6.17it/s, loss=0.733, v_num=wreq]Epoch 0: : 64it [00:10,  6.16it/s, loss=0.732, v_num=wreq]Epoch 0: : 65it [00:10,  6.25it/s, loss=0.732, v_num=wreq]Epoch 0: : 65it [00:10,  6.25it/s, loss=0.732, v_num=wreq]Epoch 0: : 66it [00:10,  6.34it/s, loss=0.732, v_num=wreq]Epoch 0: : 66it [00:10,  6.34it/s, loss=0.732, v_num=wreq]Epoch 0: : 67it [00:10,  6.42it/s, loss=0.732, v_num=wreq]Epoch 0: : 67it [00:10,  6.42it/s, loss=0.732, v_num=wreq]Epoch 0: : 68it [00:10,  6.19it/s, loss=0.732, v_num=wreq]Epoch 0: : 68it [00:10,  6.19it/s, loss=0.732, v_num=wreq]Epoch 0: : 69it [00:11,  6.27it/s, loss=0.732, v_num=wreq]Epoch 0: : 69it [00:11,  6.27it/s, loss=0.732, v_num=wreq]Epoch 0: : 70it [00:11,  6.35it/s, loss=0.732, v_num=wreq]Epoch 0: : 70it [00:11,  6.35it/s, loss=0.732, v_num=wreq]Epoch 0: : 71it [00:11,  6.43it/s, loss=0.732, v_num=wreq]Epoch 0: : 71it [00:11,  6.43it/s, loss=0.732, v_num=wreq]Epoch 0: : 72it [00:11,  6.23it/s, loss=0.732, v_num=wreq]Epoch 0: : 72it [00:11,  6.23it/s, loss=0.732, v_num=wreq]Epoch 0: : 73it [00:11,  6.31it/s, loss=0.732, v_num=wreq]Epoch 0: : 73it [00:11,  6.31it/s, loss=0.732, v_num=wreq]Epoch 0: : 74it [00:11,  6.39it/s, loss=0.732, v_num=wreq]Epoch 0: : 74it [00:11,  6.39it/s, loss=0.732, v_num=wreq]Epoch 0: : 75it [00:11,  6.47it/s, loss=0.732, v_num=wreq]Epoch 0: : 75it [00:11,  6.47it/s, loss=0.732, v_num=wreq]Epoch 0: : 76it [00:12,  6.27it/s, loss=0.732, v_num=wreq]Epoch 0: : 76it [00:12,  6.27it/s, loss=0.732, v_num=wreq]Epoch 0: : 77it [00:12,  6.35it/s, loss=0.732, v_num=wreq]Epoch 0: : 77it [00:12,  6.35it/s, loss=0.732, v_num=wreq]Epoch 0: : 78it [00:12,  6.42it/s, loss=0.732, v_num=wreq]Epoch 0: : 78it [00:12,  6.42it/s, loss=0.732, v_num=wreq]Epoch 0: : 79it [00:12,  6.50it/s, loss=0.732, v_num=wreq]Epoch 0: : 79it [00:12,  6.49it/s, loss=0.732, v_num=wreq]Epoch 0: : 80it [00:12,  6.32it/s, loss=0.732, v_num=wreq]Epoch 0: : 80it [00:12,  6.32it/s, loss=0.732, v_num=wreq]Epoch 0: : 81it [00:12,  6.39it/s, loss=0.732, v_num=wreq]Epoch 0: : 81it [00:12,  6.39it/s, loss=0.732, v_num=wreq]Epoch 0: : 82it [00:12,  6.47it/s, loss=0.732, v_num=wreq]Epoch 0: : 82it [00:12,  6.47it/s, loss=0.732, v_num=wreq]Epoch 0: : 83it [00:12,  6.54it/s, loss=0.732, v_num=wreq]Epoch 0: : 83it [00:12,  6.54it/s, loss=0.732, v_num=wreq]Epoch 0: : 84it [00:13,  6.36it/s, loss=0.732, v_num=wreq]Epoch 0: : 84it [00:13,  6.36it/s, loss=0.732, v_num=wreq]Epoch 0: : 85it [00:13,  6.42it/s, loss=0.732, v_num=wreq]Epoch 0: : 85it [00:13,  6.42it/s, loss=0.731, v_num=wreq]Epoch 0: : 86it [00:13,  6.49it/s, loss=0.731, v_num=wreq]Epoch 0: : 86it [00:13,  6.49it/s, loss=0.731, v_num=wreq]Epoch 0: : 87it [00:13,  6.56it/s, loss=0.731, v_num=wreq]Epoch 0: : 87it [00:13,  6.56it/s, loss=0.731, v_num=wreq]Epoch 0: : 88it [00:13,  6.37it/s, loss=0.731, v_num=wreq]Epoch 0: : 88it [00:13,  6.37it/s, loss=0.731, v_num=wreq]Epoch 0: : 89it [00:13,  6.44it/s, loss=0.731, v_num=wreq]Epoch 0: : 89it [00:13,  6.44it/s, loss=0.731, v_num=wreq]Epoch 0: : 90it [00:13,  6.50it/s, loss=0.731, v_num=wreq]Epoch 0: : 90it [00:13,  6.50it/s, loss=0.731, v_num=wreq]Epoch 0: : 91it [00:13,  6.57it/s, loss=0.731, v_num=wreq]Epoch 0: : 91it [00:13,  6.57it/s, loss=0.731, v_num=wreq]Epoch 0: : 92it [00:14,  6.31it/s, loss=0.731, v_num=wreq]Epoch 0: : 92it [00:14,  6.31it/s, loss=0.731, v_num=wreq]Epoch 0: : 93it [00:14,  6.37it/s, loss=0.731, v_num=wreq]Epoch 0: : 93it [00:14,  6.37it/s, loss=0.731, v_num=wreq]Epoch 0: : 94it [00:14,  6.44it/s, loss=0.731, v_num=wreq]Epoch 0: : 94it [00:14,  6.44it/s, loss=0.731, v_num=wreq]Epoch 0: : 95it [00:14,  6.50it/s, loss=0.731, v_num=wreq]Epoch 0: : 95it [00:14,  6.50it/s, loss=0.731, v_num=wreq]Epoch 0: : 96it [00:15,  6.34it/s, loss=0.731, v_num=wreq]Epoch 0: : 96it [00:15,  6.34it/s, loss=0.731, v_num=wreq]Epoch 0: : 97it [00:15,  6.39it/s, loss=0.731, v_num=wreq]Epoch 0: : 97it [00:15,  6.39it/s, loss=0.731, v_num=wreq]Epoch 0: : 98it [00:15,  6.45it/s, loss=0.731, v_num=wreq]Epoch 0: : 98it [00:15,  6.45it/s, loss=0.731, v_num=wreq]Epoch 0: : 99it [00:15,  6.51it/s, loss=0.731, v_num=wreq]Epoch 0: : 99it [00:15,  6.50it/s, loss=0.73, v_num=wreq] Epoch 0: : 100it [00:15,  6.37it/s, loss=0.73, v_num=wreq]Epoch 0: : 100it [00:15,  6.37it/s, loss=0.73, v_num=wreq]Error executing job with overrides: ['training.accelerator=gpu', 'project.wandb_mode=run']
Traceback (most recent call last):
  File "/faststorage/project/NLPPred/github/snip/src/snip/train_slided_autoencoder.py", line 209, in main
    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1283, in _run_train
    self.fit_loop.run()
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py", line 201, in run
    self.on_advance_end()
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 299, in on_advance_end
    self.trainer._call_callback_hooks("on_train_epoch_end")
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1597, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/callbacks/early_stopping.py", line 183, in on_train_epoch_end
    self._run_early_stopping_check(trainer)
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/callbacks/early_stopping.py", line 194, in _run_early_stopping_check
    if trainer.fast_dev_run or not self._validate_condition_metric(  # disable early_stopping with fast_dev_run
  File "/home/kce/miniconda3/envs/snip2/lib/python3.9/site-packages/pytorch_lightning/callbacks/early_stopping.py", line 149, in _validate_condition_metric
    raise RuntimeError(error_msg)
RuntimeError: Early stopping conditioned on metric `Validation loss` which is not available. Pass in or modify your `EarlyStopping` callback to use any of the following: `Training loss`, `Training step/sec`

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: - 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: - 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.016 MB of 0.016 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:        Model number ‚ñÅ
wandb:            N models ‚ñÅ
wandb:       Training loss ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   Training step/sec ‚ñÉ‚ñà‚ñÑ‚ñà‚ñÅ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÅ
wandb:               epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: trainer/global_step ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:        Model number 0
wandb:            N models 3
wandb:       Training loss 0.72902
wandb:   Training step/sec 0.00127
wandb:               epoch 0
wandb: trainer/global_step 99
wandb: 
wandb: Synced clear-bird-23: https://wandb.ai/kenevoldsen/local%20mlp/runs/1kzcwreq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221001_012731-1kzcwreq/logs
Epoch 0: : 100it [00:24,  4.13it/s, loss=0.73, v_num=wreq]